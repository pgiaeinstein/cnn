{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B203wlF-lAUi"
   },
   "source": [
    "# Atividade 1 - Redes Neurais Convolucionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KHaTQIXjlAUk"
   },
   "source": [
    "## Visão Computacional\n",
    "\n",
    "Visão computacional é a ciência e tecnologia das máquinas que enxergam. Ela desenvolve teoria e tecnologia para a construção de sistemas artificiais que obtém informação de imagens ou quaisquer dados multidimensionais. Exemplos de aplicações incluem o controle de processos (como robôs industriais ou veículos autônomos), detecção de eventos, organização de informação, modelagem de objetos ou ambientes e interação (atrelado a interação humano-computador).\n",
    "\n",
    "A visão computacional também pode ser descrita como um complemento da visão biológica. Na visão biológica, a percepção visual dos humanos e outros animais é estudada, resultando em modelos em como tais sistemas operam em termos de processos fisiológicos. Por outro lado, a visão computacional estuda e descreve sistemas de visão artificial implementados por hardware ou software.\n",
    "\n",
    "Subcampos de pesquisa incluem reconstrução de cena, detecção de eventos, reconhecimento de objetos, aprendizagem de máquina e restauração de imagens.\n",
    "\n",
    "[Fonte - Wikipedia](https://pt.wikipedia.org/wiki/Vis%C3%A3o_computacional)\n",
    "\n",
    "### Literatura recomendada\n",
    "\n",
    "Para aqueles que tem interesse em um domínio maior em visão computacional, recomendo a leitura do livro [Processamento Digital de Imagens - Digital Image Processing (Gonzalez, Woods)](https://www.amazon.com.br/Digital-Image-Processing-Rafael-Gonzalez/dp/0133356728/ref=pd_lpo_sbs_14_img_0?_encoding=UTF8&psc=1&refRID=VNRJ5DV5YG8BHZF77FGT) muito utilizado como livro texto nas disciplinas de computação gráfica em cursos de ciências da computação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YU_TRU3klAUm"
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RP680A41lAUu"
   },
   "source": [
    "### Exemplos de aplicação\n",
    "\n",
    "#### Detecção de veículos e cálculo de velocidade através de câmeras de monitoramento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2P1ne5IYlAUv"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('inCUJ0JM5ng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fu4SJu55lAU0"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('HLs_0obPh74')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BdZVT495lAU5"
   },
   "source": [
    "#### Aplicação de redes neurais para detecção de entidades\n",
    "\n",
    "Exemplo abaixo mostra aplicação de uma rede conhecida [YOLO](https://pjreddie.com/darknet/yolo/) aplicada para detecção de objetos em tempo real.\n",
    "\n",
    "Yolo é conhecida por ser uma rede eficiente e performática, permitindo sua utilização através de dispositivos como uma [Raspberry Pi](https://www.raspberrypi.org/products/raspberry-pi-3-model-b/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsETJPFWlAU5"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('MPU2HistivI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jinTYEb4lAU-"
   },
   "outputs": [],
   "source": [
    "!wget \"https://github.com/pgiaeinstein/aula-09/raw/master/img1.dcm\"\n",
    "!wget \"https://github.com/pgiaeinstein/aula-09/raw/master/img2.dcm\"\n",
    "!wget \"https://github.com/pgiaeinstein/cnn/raw/master/imagens/castelo.png\"\n",
    "!wget \"https://github.com/pgiaeinstein/cnn/raw/master/imagens/estrada.jpg\"\n",
    "!wget \"https://github.com/pgiaeinstein/cnn/raw/master/imagens/lenna.png\"\n",
    "!wget \"https://github.com/pgiaeinstein/cnn/raw/master/imagens/moedas.jpg\"\n",
    "!wget \"https://github.com/pgiaeinstein/cnn/raw/master/imagens/noguchi.jpg\"\n",
    "!wget \"https://github.com/pgiaeinstein/cnn/raw/master/imagens/oy.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SS48KwHGlAVD"
   },
   "outputs": [],
   "source": [
    "# DICOM\n",
    "dicom_img_1 = './img1.dcm'\n",
    "dicom_img_2 = './img2.dcm'\n",
    "# Imagens\n",
    "img_castelo = './castelo.png'\n",
    "img_estrada = './estrada.jpg'\n",
    "img_lenna   = './lenna.png'\n",
    "img_moedas  = './moedas.jpg'\n",
    "img_noguchi = './noguchi.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UARyrDlalAVH"
   },
   "outputs": [],
   "source": [
    "import matplotlib, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePPFZnl8lAVK"
   },
   "source": [
    "#### Lib OpenCV\n",
    "\n",
    "OpenCV (Open Source Computer Vision Library). Originalmente, desenvolvida pela Intel, em 2000, é uma biblioteca multiplataforma, totalmente livre ao uso acadêmico e comercial, para o desenvolvimento de aplicativos na área de Visão computacional, bastando seguir o modelo de licença BSD Intel. O OpenCV possui módulos de Processamento de Imagens e Video I/O, Estrutura de dados, Álgebra Linear, GUI (Interface Gráfica do Usuário) Básica com sistema de janelas independentes, Controle de mouse e teclado, além de mais de 350 algoritmos de Visão computacional como: Filtros de imagem, calibração de câmera, reconhecimento de objetos, análise estrutural e outros. O seu processamento é em tempo real de imagens.\n",
    "\n",
    "[Fonte - Wikipedia](https://pt.wikipedia.org/wiki/OpenCV)\n",
    "\n",
    "#### Python-OpenCV\n",
    "\n",
    "OpenCV possui uma biblioteca dedicada em [Python](https://pypi.org/project/opencv-python/) sua documentação pode ser consultada neste [link](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p4Wy1gwrlAVL"
   },
   "outputs": [],
   "source": [
    "# Lendo um arquivo de imagem utilizando opencv\n",
    "img = cv2.imread(img_lenna, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EGa-njknlAVO"
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ky8R8j4-lAVS"
   },
   "source": [
    "O resultado da operação de leitura é uma matriz de dimensão (linha, coluna). Por padrão, `cv2` carrega vetores em BGR mas podemos modificar para RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnYoBMBWlAVT"
   },
   "outputs": [],
   "source": [
    "# Uma imagem de 512x512 pixel em 3 canais de informação\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59-XqPE7lAVY"
   },
   "outputs": [],
   "source": [
    "# Utilizando matplotlib, a função imshow permite o plot de imagens\n",
    "# a configuração off em axis remove os eixos do gráfico padrão\n",
    "plt.axis('off')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1d-ShbPIlAVa"
   },
   "source": [
    "Por exemplo, a imagem carregada possui 512x512 px onde cada pixel tem 3 canais (BGR).\n",
    "\n",
    "#### Convertendo BGR para RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZLsyrSflAVc"
   },
   "outputs": [],
   "source": [
    "# O método cvtColor permite modificar o esquema de cores entre os 3 canais da estrutura de dados\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1tUMz4TlAVg"
   },
   "source": [
    "#### RGB para GrayScale\n",
    "\n",
    "Essa transformação vai atacar os 3 canais condensando sua informação em apenas um canal variando em preto e branco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldun3NSNlAVg"
   },
   "outputs": [],
   "source": [
    "# Por exemplo modificando os canais para que todos sejam equalizados em um\n",
    "# range de 0 - 255 (0 - preto; 255 - branco) tornando a imagem preto e branco\n",
    "img_pb = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kfu4YfsFlAVj"
   },
   "outputs": [],
   "source": [
    "# Uma imagem de 512x512 pixel com 1 canal de informação\n",
    "img_pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VnYOEBGelAVn"
   },
   "outputs": [],
   "source": [
    "# Uma imagem de 512x512 pixel com 1 canal de informação\n",
    "img_pb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8KxZSRkslAVq"
   },
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(img_pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXWYv6L5lAVs"
   },
   "outputs": [],
   "source": [
    "# imshow espera 3 uma estrutura de dados com 3 canais de informação, podemos resolver o\n",
    "# problema com uma nova transformação, voltando a estrutura para RGB\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(img_pb, cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YF7XQFTblAVv"
   },
   "source": [
    "#### Máscaras por filtro de banda\n",
    "\n",
    "Podemos criar um filtro que resulta em uma máscara binária de informação, vejamos a imagem de exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AsDqqcQvlAVw"
   },
   "outputs": [],
   "source": [
    "estrada = cv2.imread(img_estrada)\n",
    "# Repare que vamos utilizar uma outra representação de domínio de cores, no\n",
    "# caso o HSV (hue, saturation, value)\n",
    "estrada_hsv = cv2.cvtColor(estrada, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(estrada_hsv, cv2.COLOR_HSV2RGB))\n",
    "# plt.imshow(estrada_hsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iMDT_9xPlAVy"
   },
   "source": [
    "Verifique que fizemos uma operação para transformar o sistema de cores para seu representativo HSV (**H**ue [matriz], **S**aturation [saturação] e **V**alue [valor]).\n",
    "\n",
    "Se os limites superior e inferior forem conhecidos, podemos criar um filtro capaz de segmentar a imagem da forma que desejamos, por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MDMd-cm4lAVz"
   },
   "outputs": [],
   "source": [
    "# Os limítes inferior e superior para encontrar nossa região de interesse\n",
    "azul_inferior = np.array([85, 60, 60], np.uint8)\n",
    "azul_superior = np.array([150, 255, 255], np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2ip91T7lAV2"
   },
   "outputs": [],
   "source": [
    "# inRange varre a estrutura buscando por pixels dentro de um certo limite de busca\n",
    "# em nosso exemplo, executa um filtro de passa banda na imagem\n",
    "mask_inverse = cv2.inRange(estrada_hsv, azul_inferior, azul_superior)\n",
    "# Operação bit-a-bit na estrutura de dado\n",
    "mask = cv2.bitwise_not(mask_inverse)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-X4PwhyblAV5"
   },
   "source": [
    "Podemos então realizar a subtração dos elementos que não compreendem a máscara criada, veja exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g7p_l463lAV6"
   },
   "outputs": [],
   "source": [
    "mask_rgb = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)\n",
    "masked_estrada = cv2.bitwise_and(estrada, mask_rgb)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(masked_estrada, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "liQN6vFJtj35"
   },
   "outputs": [],
   "source": [
    "# Faz a imagem \"sangrar\" trocando os pixels [0, 0, 0] por seu relativo [1, 1, 1]\n",
    "masked_replace_branco = cv2.addWeighted(masked_estrada, 1, cv2.cvtColor(mask_inverse, cv2.COLOR_GRAY2RGB), 1, 0)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.axis('off')\n",
    "plt.imshow(cv2.cvtColor(masked_replace_branco, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RttNtfH3lAV-"
   },
   "source": [
    "### Filtro Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjWDNNmDxwKR"
   },
   "outputs": [],
   "source": [
    "def aplica_sobel(imagem):\n",
    "  \n",
    "    img = cv2.imread(imagem, 0)\n",
    "\n",
    "    # Aplica o kernel sobel em x e y na imagem original, calculando a magnitude\n",
    "    # no final da operação\n",
    "    sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "    sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "    sobel_g = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    sobel_g *= 255.0 / np.max(sobel_g)\n",
    "\n",
    "    # Cria uma figura para 4 plots, plota em cada posição o resultado de cada\n",
    "    # etapa do processamento acima\n",
    "    plt.figure(1, figsize = (15, 15))\n",
    "    plt.subplot(221),plt.imshow(img, cmap = 'gray')\n",
    "    plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(222),plt.imshow(sobel_x, cmap = 'gray')\n",
    "    plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(223),plt.imshow(sobel_y, cmap = 'gray')\n",
    "    plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(224),plt.imshow(sobel_g, cmap = 'gray')\n",
    "    plt.title('Sobel G'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McVEgVBOlAWC"
   },
   "outputs": [],
   "source": [
    "aplica_sobel(img_lenna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHkQVn8JlAWE"
   },
   "outputs": [],
   "source": [
    "aplica_sobel(img_castelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6f_-scOtlAWH"
   },
   "source": [
    "### Desafio rápido\n",
    "\n",
    "Aplique a função `aplica_sobel(img_entrada)` nas outras imagens carregadas, vamos discutir os resultados obtidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JunO__e9lAWJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2GRxtSs7whfK"
   },
   "source": [
    "# Trabalhando com arquivos DICOM\n",
    "\n",
    "## O que é DICOM?\n",
    "\n",
    "- DICOM - Digital Imaging and Communications in Medicine;\n",
    "\n",
    "- Conjunto de normas para tratamento, armazenamento e transmissão de informação médica (PROTOCOLO);\n",
    " - Padroniza a formatação das imagens diagnósticas como tomografias, ressonâncias magnéticas, radiografias, ultrassonografias, etc...;\n",
    "  - Permite que imagens médicas e informações associadas sejam trocadas entre equipamentos de diagnóstico geradores de imagens, computadores e hospitais, ou seja, estabelece uma linguagem comum entre os equipamentos de diferentes marcas.\n",
    "\n",
    "[Wikipedia](https://pt.wikipedia.org/wiki/DICOM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPKWuCjuzZ0l"
   },
   "source": [
    "## Protocolo?\n",
    "\n",
    "- Convenção que controla e possibilita uma conexão, comunicação, transferência de dados entre dois sistemas computacionais.\n",
    "\n",
    "- Define regras de sintaxe, semântica e sincronização da comunicação.\n",
    "\n",
    "---\n",
    "\n",
    "| Protocolo | Descrição |\n",
    "|--|--|\n",
    "| IP | [Internet Protocol](https://pt.wikipedia.org/wiki/Internet_Protocol \"Internet Protocol\") |\n",
    "| HTTP | [Hypertext Transfer Protocol](https://pt.wikipedia.org/wiki/HTTP \"HTTP\") |\n",
    "| POP3 | [Post Office Protocol](https://pt.wikipedia.org/wiki/Post_Office_Protocol \"Post Office Protocol\") |\n",
    "| SMTP | [Simple Mail Transfer Protocol](https://pt.wikipedia.org/wiki/Simple_Mail_Transfer_Protocol \"Simple Mail Transfer Protocol\") |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hi2gErwm2kx7"
   },
   "source": [
    "## PyDICOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "528U4dMC3NUO"
   },
   "outputs": [],
   "source": [
    "# É necessário instalar o pacote pydicom pelo gerenciador de pacotes pip\n",
    "!pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eH5vxT9w2kHY"
   },
   "outputs": [],
   "source": [
    "# Após isso, podemos importar o pacote\n",
    "import pydicom\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cNuZGTj82f2N"
   },
   "outputs": [],
   "source": [
    "# O método read_file permite carregar a estrutura de um arquivo em formato dicom (dcm)\n",
    "dcmdata = pydicom.read_file('./img1.dcm')\n",
    "print(dcmdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaofMvxVbwnB"
   },
   "outputs": [],
   "source": [
    "# pixel_array é a forma de consultar a posição onde na estrutura\n",
    "# encontramos a imagem no arquivo dicom (campo Pixel Data da estrutura)\n",
    "# Lembrando que o domínio de cores desta estrutura é descrito em (Photometric Interpretation)\n",
    "dcmimg = dcmdata.pixel_array\n",
    "print(dcmimg.dtype)\n",
    "print(dcmimg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uo8BULvnbywx"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "# plt.imshow(dcmimg)\n",
    "plt.imshow(dcmimg, cmap='bone')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJ0vLl5r-Wtg"
   },
   "source": [
    "### Desafio\n",
    "\n",
    "Repita o processo acima para o arquivo img2.dcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcU-uqpiq2bi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RaQviU9twJrn"
   },
   "source": [
    "# Hello Word CNN - MNIST\n",
    "\n",
    "O objetivo desta atividade é familiarizar o aluno com uma CNN. Utilizaremos  o dataset __MNIST__ para treinar uma CNN para classificar números manuscritos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow\n",
    "!pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_a5I_VW0Ic5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D, Conv2D\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdGGpVJO0NUh"
   },
   "outputs": [],
   "source": [
    "# Recebe os dados para treino e teste do dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "nb_classes = 10\n",
    "\n",
    "# Asseguro que a informação é do tipo float\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# Modifico os limites da informação para respeitar um range entre 0...1\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8aKxOiLa2OAc"
   },
   "source": [
    "Vamos exibir algumas imagens deste dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJBVwmju1df4"
   },
   "outputs": [],
   "source": [
    "# plot simples de 10 exemplos de imagens no dataset\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(cv2.cvtColor(X_train[i], cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5PxQ8S6D0cRy"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# Asseguro que todas as estruturas respeitam o formato (28, 28, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-PqXto3i0qot"
   },
   "outputs": [],
   "source": [
    "nb_filters = 32\n",
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(nb_filters, kernel_size, padding='same', input_shape=input_shape, activation='relu', name='Conv2DLayer1'))\n",
    "model.add(Conv2D(nb_filters, kernel_size, padding='same',activation='relu', name='Conv2DLayer2'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, padding=\"same\", name='MaxPoolLayer3'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu', name='DenseLayer4'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=nb_classes, activation='softmax', name='OutputLayer4'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPyDe3Kx0p33"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='model.hdf5', monitor='val_acc', verbose=True, save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=128, validation_split=0.1, verbose=1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_camadas = [camada.output for camada in model.layers[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = Model(inputs=model.input, outputs=output_camadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código adaptado de Deep Learning With Python; François Chollet; Pg 164\n",
    "def model_layers_output(imagem):\n",
    "\n",
    "    activations_output = activations.predict([[imagem]])\n",
    "    \n",
    "    layers = list()\n",
    "    \n",
    "    for layer in model.layers[:3]:\n",
    "        layers.append(layer.name)\n",
    "\n",
    "    grid_imgs = 16\n",
    "\n",
    "    for layer_name, activation_output in zip(layers, activations_output):\n",
    "        features = activation_output.shape[-1]\n",
    "        activation_size = activation_output.shape[1]\n",
    "        numb_cols = features // grid_imgs\n",
    "        display_grid = np.zeros((activation_size * numb_cols, grid_imgs * activation_size))\n",
    "        \n",
    "        for col in range(numb_cols):\n",
    "            for row in range(grid_imgs):\n",
    "                heatmap = activation_output[0, :, :, col * grid_imgs + row]\n",
    "                heatmap -= heatmap.mean()\n",
    "                heatmap /= heatmap.std()\n",
    "                heatmap *= 64\n",
    "                heatmap += 128\n",
    "                heatmap = np.clip(heatmap, 0, 255)\n",
    "                display_grid[col * activation_size : (col + 1) * activation_size, row * activation_size : (row + 1) * activation_size] = heatmap\n",
    "                \n",
    "        scale = 1. / activation_size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(display_grid, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers_output(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers_output(X_test[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers_output(X_test[90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers_output(X_test[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9yreCG6S3XmG"
   },
   "outputs": [],
   "source": [
    "# Função plota imagens onde a rede teve como output uma classificação errada\n",
    "def mostrar_erros(predictions, trueclass=None, predictedclass=None, maxtoshow=10):\n",
    "   \n",
    "    rounded = np.argmax(predictions, axis=1)\n",
    "    errors = rounded!=y_test\n",
    "\n",
    "    ii = 0\n",
    "    plt.figure(figsize=(maxtoshow, 1))\n",
    "    for i in range(X_test.shape[0]):\n",
    "        if ii>=maxtoshow:\n",
    "            break\n",
    "        if errors[i]:\n",
    "            if trueclass is not None and y_test[i] != trueclass:\n",
    "                continue\n",
    "            if predictedclass is not None and predictions[i] != predictedclass:\n",
    "                continue\n",
    "            plt.subplot(1, maxtoshow, ii+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(X_test[i,:,:,0], cmap=\"gray\")\n",
    "            # informando [classificação (saída correta)]\n",
    "            plt.title(\"%d (%d)\" % (rounded[i], y_test[i]))\n",
    "            ii = ii + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILxQNq4u5aJb"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "\n",
    "mostrar_erros(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZqjQl3-D5gre"
   },
   "outputs": [],
   "source": [
    "mostrar_erros(preds, trueclass = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LlA4lpc2wKDf"
   },
   "source": [
    "# Kmeans\n",
    "\n",
    "Em nossa próxima atividade, vamos tentar segmentar uma imagem utilizando uma U-Net.\n",
    "\n",
    "Para possibilitar o treinamento desta rede, precisamos criar máscaras de segmentação, ou seja, o que esperamos que a rede responda quando receber uma imagem para analisar.\n",
    "\n",
    "Uma forma simples de fazer isso é aplicar K-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xsHfH4jlAW4"
   },
   "source": [
    "## Kmeans um exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLnMZk5ZlAW5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from time import time\n",
    "import cv2\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m10ktNNwlAW7"
   },
   "outputs": [],
   "source": [
    "# Função cria estrutura de retorno da imagem, substituindo cada classe por seu\n",
    "# valor relativo ao pixel dominante do cluster\n",
    "def label_para_pixel(bloco, labels, l, a):\n",
    "    dimensao = bloco.shape[1]\n",
    "    imagem = np.zeros((l, a, dimensao))\n",
    "    index = 0\n",
    "    for i in range(l):\n",
    "        for j in range(a):\n",
    "            imagem[i][j] = bloco[labels[index]]\n",
    "            index += 1\n",
    "    return imagem\n",
    "\n",
    "# Função aplica o modelo K-means na imagem com K número de pixel\n",
    "def retorna_kmeans(n_cores, img_input):\n",
    "    \n",
    "    # Carrega a imagem, normaliza a estrutura para o range 0...1\n",
    "    img = cv2.imread(img_input)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.array(img, dtype = np.float64) / 255\n",
    "\n",
    "    # assegura que todas as imagens têm 3 canais e modifica sua estrutura\n",
    "    # para uma lista de vetores com 3 posições\n",
    "    w, h, d = tuple(img.shape)\n",
    "    assert d == 3\n",
    "    image_array = np.reshape(img, (w * h, d))\n",
    "    print(image_array.shape)\n",
    "\n",
    "    # Treina um modelo K-means para encontrar os pixels mais dominantes na imagem\n",
    "    # Label recebe a lista de outputs do modelo\n",
    "    kmeans = KMeans(n_clusters = n_cores, random_state = 0).fit(image_array)\n",
    "    labels = kmeans.predict(image_array)\n",
    " \n",
    "    plt.figure(1, figsize = (15, 15))\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('Imagem original')\n",
    "    ax1.imshow(img)\n",
    "\n",
    "    ax2 = plt.subplot(122)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title('Imagem K-Means')\n",
    "    ax2.imshow(label_para_pixel(kmeans.cluster_centers_, labels, w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5w_1tuDlAW9"
   },
   "outputs": [],
   "source": [
    "k_cores = 4\n",
    "\n",
    "retorna_kmeans(k_cores, img_castelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIRRRhhclAXA"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('yR7k19YBqiw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rVTsdPulAXB"
   },
   "source": [
    "### Desafio\n",
    "\n",
    "Repita o processo acima variando o número de k-clusters com as imagens carregadas nos exemplos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7LYB72blAXC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDGWYefS7pe8"
   },
   "outputs": [],
   "source": [
    "!wget \"https://github.com/pgiaeinstein/aula-10/raw/master/original_imgs.zip\"\n",
    "!unzip original_imgs.zip\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "742DA38KlAXG"
   },
   "source": [
    "### Kmeans aplicado\n",
    "\n",
    "Vamos aplicar a técnica demonstrada acima para gerar máscaras de uma série de imagens de células sanguíneas, veja que modificamos um pouco a função `label_para_pixel()` para que o output seja um resultante binário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExgjGvbb70KE"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import cv2\n",
    "\n",
    "def label_para_pixel(bloco, labels, l, a):\n",
    "    dimensao = bloco.shape[1]\n",
    "    imagem = np.zeros((l, a, dimensao))\n",
    "    index = 0\n",
    "        \n",
    "    if bloco[0][0] > bloco[1][0]:\n",
    "        cor_cell = [1., 1., 1.]\n",
    "        cor_fundo = [0., 0., 0.]\n",
    "    else:\n",
    "        cor_cell = [0., 0., 0.]\n",
    "        cor_fundo = [1., 1., 1.]\n",
    "    \n",
    "    for i in range(l):\n",
    "        for j in range(a):\n",
    "            if labels[index] == 0:\n",
    "                imagem[i][j] = cor_fundo\n",
    "            else:\n",
    "                imagem[i][j] = cor_cell\n",
    "            index += 1\n",
    "    return imagem\n",
    "\n",
    "def retorna_kmeans(n_cores, img_path):\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img = np.array(img, dtype = np.float64) / 255\n",
    "\n",
    "    w, h, d = tuple(img.shape)\n",
    "    assert d == 3\n",
    "    image_array = np.reshape(img, (w * h, d))\n",
    "\n",
    "    kmeans = KMeans(n_clusters = n_cores, random_state = 0).fit(image_array)\n",
    "    labels = kmeans.predict(image_array)\n",
    "    img_mask = label_para_pixel(kmeans.cluster_centers_, labels, w, h)\n",
    "    return img, img_rgb, img_mask\n",
    "    \n",
    "    \n",
    "def plota_imagens(img, img_mask):\n",
    "    plt.figure(1, figsize = (15, 15))\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('Imagem original')\n",
    "    ax1.imshow(img)\n",
    "\n",
    "    ax2 = plt.subplot(122)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title('Imagem K-Means')\n",
    "    ax2.imshow(img_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROTIXOPVlSpw"
   },
   "source": [
    "Vamos imprimir o resultado da clusterização de uma imagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EUcQAoXQ8NvF"
   },
   "outputs": [],
   "source": [
    "img = './original_imgs/BloodImage_00002.jpg'\n",
    "\n",
    "img, img_rgb, img_mask = retorna_kmeans(2, img)\n",
    "plota_imagens(img_rgb, img_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "moIVc3bDljMw"
   },
   "source": [
    "Vamos automatizar a criação de nossa base de treino e teste.\n",
    "\n",
    "A função abaixo percorrerá todo o conteúdo da pasta de imagens original e aplicará o processo de clusterização separando em imagem original e máscara criada em duas pastas distintas para facilitar o _import_ dos dados no exercício futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Je0hsXs8Z4h"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "from tqdm import tqdm\n",
    "\n",
    "IMAGENS_PATH = './imgs_originais'\n",
    "MASKS_PATH = './masks_lab'\n",
    "\n",
    "WORK_PATH = './original_imgs'\n",
    "\n",
    "try:\n",
    "    os.makedirs(IMAGENS_PATH)\n",
    "    os.makedirs(MASKS_PATH)\n",
    "except OSError as e:\n",
    "    if e.errno != errno.EEXIST:\n",
    "        raise\n",
    "        \n",
    "lista_imagens = os.listdir(WORK_PATH)\n",
    "\n",
    "for imagem in tqdm(lista_imagens):\n",
    "    img_nome = imagem.replace('.jpg', '')\n",
    "    img, _, img_mask = retorna_kmeans(2, os.path.join(WORK_PATH, imagem))\n",
    "    cv2.imwrite(os.path.join(IMAGENS_PATH, '{0}.jpg'.format(img_nome)), img * 255)\n",
    "    cv2.imwrite(os.path.join(MASKS_PATH, '{0}_mask.jpg'.format(img_nome)), img_mask * 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2olS1SNOwKWH"
   },
   "source": [
    "# CNN\n",
    "\n",
    "Vamos implementar uma U-Net e nosso objetivo é conseguir segmentar as imagens de células sanguíneas que processamos no exemplo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WHCuoxQlAXO"
   },
   "outputs": [],
   "source": [
    "!wget \"https://github.com/pgiaeinstein/cnn/raw/master/imagens/bc.zip\"\n",
    "!unzip bc.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODNLPGHKKgr-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "mpl.style.use('fivethirtyeight')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQ9VRReUQxXi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import functools\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib as tfcontrib\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras import models\n",
    "from tensorflow.python.keras import backend as K  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uf1B2NRBlAXV"
   },
   "source": [
    "## Preparando os arquivos de entrada\n",
    "\n",
    "Disponibilizamos um _zip_ contendo duas pastas (`imgs` e `masks`) uma contendo as imagens originais e outra as máscaras geradas pelo processo descrito acima.\n",
    "\n",
    "O objetivo desta etapa é verificar se os diretórios foram carregados da maneira correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wT1kb3q0ghhi"
   },
   "outputs": [],
   "source": [
    "img_dir = './imgs'\n",
    "label_dir = './masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "33i4xFXweztH"
   },
   "outputs": [],
   "source": [
    "X_train_imgs = os.listdir(img_dir)\n",
    "y_train_filenames = os.listdir(label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NI9j0vxelAXY"
   },
   "outputs": [],
   "source": [
    "X_train_imgs.sort()\n",
    "y_train_filenames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMcwqpm9lAXa"
   },
   "outputs": [],
   "source": [
    "X_train_imgs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bO5jgqoolAXb"
   },
   "outputs": [],
   "source": [
    "y_train_filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lDS_cya_lAXc"
   },
   "outputs": [],
   "source": [
    "for index, img_path in enumerate(X_train_imgs):\n",
    "    X_train_imgs[index] = os.path.join(img_dir, img_path)\n",
    "    \n",
    "for index, img_path in enumerate(y_train_filenames):\n",
    "    y_train_filenames[index] = os.path.join(label_dir, img_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtutNudKbf70"
   },
   "outputs": [],
   "source": [
    "X_train_imgs, x_val_filenames, y_train_filenames, y_val_filenames = train_test_split(X_train_imgs, y_train_filenames, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Di1N83ArilzR"
   },
   "outputs": [],
   "source": [
    "X_train_imgs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gc-BDv1Zio1z"
   },
   "outputs": [],
   "source": [
    "y_train_filenames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-bgizz3lAXi"
   },
   "source": [
    "Para verificar se as imagens estão sendo carregadas de forma correta, vamos mostrar 5 exemplos. A imagem original deve ser exibida ao lado de sua máscara correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7W1Ut-I5Nwi"
   },
   "outputs": [],
   "source": [
    "num_train_examples = len(X_train_imgs)\n",
    "num_val_examples = len(x_val_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUA6SDLhozjj"
   },
   "outputs": [],
   "source": [
    "display_num = 5\n",
    "\n",
    "r_choices = np.random.choice(num_train_examples, display_num)\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "\n",
    "for i in range(0, display_num * 2, 2):\n",
    "    \n",
    "    img_num = r_choices[i // 2]\n",
    "    x_pathname = X_train_imgs[img_num]\n",
    "    y_pathname = y_train_filenames[img_num]\n",
    "\n",
    "    plt.subplot(display_num, 2, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(mpimg.imread(x_pathname))\n",
    "    plt.title(\"Imagem original\")\n",
    "\n",
    "    example_labels = Image.open(y_pathname)\n",
    "    label_vals = np.unique(example_labels)\n",
    "\n",
    "    plt.subplot(display_num, 2, i + 2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(example_labels)\n",
    "    plt.title(\"Máscara da imagem\")  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CEpZEsiLlAXl"
   },
   "source": [
    "### Configurações\n",
    "\n",
    "Vamos definir como nossa rede será treinada.\n",
    "\n",
    "1. `img_shape` configura qual é o shape do vetor de entrada da rede, as imagens fora deste padrão serão manipuladas.\n",
    "2. `batch_size` configura o tamanho do batch para cada processamento realizado.\n",
    "3. `epochs` configura o número de épocas de nossa rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeDoiSFlothe"
   },
   "outputs": [],
   "source": [
    "img_shape = (256, 256, 3)\n",
    "batch_size = 3\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xzh5eV04lAXn"
   },
   "source": [
    "Aqui iniciamos nossas funções auxiliares para realizar as operações de data _augmentation_.\n",
    "\n",
    "O processo que será feito respeita a seguinte ordem:\n",
    "\n",
    "1. A imagem é carregada junto de sua máscara. Uma verificação é realizada para garantir que a máscara possui conteúdo binário onde `0` representa \"nada\" e `1` identifica uma célula sanguínea.\n",
    "\n",
    "2. A imagem é decodificada para uma matriz.\n",
    "\n",
    "3. O processo de _augmentation_ é realizado:\n",
    "    * `resize` configura qual a dimensão de input, caso a imagem esteja fora deste padrão, um redimensionamento será feito.\n",
    "    * `hue_delta` ajusta o _hue_ das imagens em rgb utilizando um fator variante de 0 a 0.5. Apenas a imagem original sofre a modificação.\n",
    "    * `horizontal_flip` rotaciona a imagem original em seu eixo central com uma probabilidade de 50%. Este processo deve ser aplicado tanto para a imagem original como para sua máscara.\n",
    "    * `width_shift_range` e `height_shift_range` são as medidas (fração em altura e largura) que as imagens serão movimentadas de seu eixo central original. Este processo também deve ser realizado tanto na imagem original quanto em sua máscara.\n",
    "    * `rescale` fator de redimensionamento da imagem.\n",
    "    \n",
    "4. Ordena os batchs de informação para garantir que a mesma sequência será utilizada nas épocas de processamento.\n",
    "\n",
    "Esse pipeline ocorre para cada batch processado, isso é importante para garantir performance na utilização de recurso computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fb_psznAggwr"
   },
   "outputs": [],
   "source": [
    "# Este exemplo de pipeline pode ser encontrado na própria documentação do framework\n",
    "def _process_pathnames(fname, label_path):\n",
    "    \n",
    "    img_str = tf.read_file(fname)\n",
    "    img = tf.image.decode_jpeg(img_str, channels = 3)\n",
    "\n",
    "    label_img_str = tf.read_file(label_path)\n",
    "    label_img = tf.image.decode_gif(label_img_str)[0]\n",
    "    label_img = label_img[:, :, 0]\n",
    "    label_img = tf.expand_dims(label_img, axis = -1)\n",
    "    \n",
    "    return img, label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdY046OqtGVH"
   },
   "outputs": [],
   "source": [
    "def shift_img(output_img, label_img, width_shift_range, height_shift_range):\n",
    "    if width_shift_range or height_shift_range:\n",
    "        if width_shift_range:\n",
    "            width_shift_range = tf.random_uniform([], -width_shift_range * img_shape[1],\n",
    "                                                  width_shift_range * img_shape[1])\n",
    "        if height_shift_range:\n",
    "            height_shift_range = tf.random_uniform([], -height_shift_range * img_shape[0],\n",
    "                                                   height_shift_range * img_shape[0])\n",
    "        output_img = tfcontrib.image.translate(output_img, [width_shift_range, height_shift_range])\n",
    "        label_img = tfcontrib.image.translate(label_img, [width_shift_range, height_shift_range])\n",
    "    \n",
    "    return output_img, label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OogLSplstur9"
   },
   "outputs": [],
   "source": [
    "def flip_img(horizontal_flip, tr_img, label_img):\n",
    "    if horizontal_flip:\n",
    "        flip_prob = tf.random_uniform([], 0.0, 1.0)\n",
    "        tr_img, label_img = tf.cond(tf.less(flip_prob, 0.5),\n",
    "                                lambda: (tf.image.flip_left_right(tr_img), tf.image.flip_left_right(label_img)),\n",
    "                                lambda: (tr_img, label_img))\n",
    "    return tr_img, label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "18WA0Sl3olyn"
   },
   "outputs": [],
   "source": [
    "def _augment(img, label_img, resize = None, scale = 1, hue_delta = 0, horizontal_flip = False,\n",
    "             width_shift_range = 0, height_shift_range = 0):\n",
    "    \n",
    "    if resize is not None:\n",
    "        label_img = tf.image.resize_images(label_img, resize)\n",
    "        img = tf.image.resize_images(img, resize)\n",
    "\n",
    "    if hue_delta:\n",
    "        img = tf.image.random_hue(img, hue_delta)\n",
    "\n",
    "    img, label_img = flip_img(horizontal_flip, img, label_img)\n",
    "    img, label_img = shift_img(img, label_img, width_shift_range, height_shift_range)\n",
    "    label_img = tf.to_float(label_img) * scale\n",
    "    img = tf.to_float(img) * scale\n",
    "    \n",
    "    return img, label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkNqQaR2HQbd"
   },
   "outputs": [],
   "source": [
    "def get_baseline_dataset(filenames, labels, preproc_fn = functools.partial(_augment), threads = 5, \n",
    "                         batch_size = batch_size, shuffle = True):           \n",
    "    num_x = len(filenames)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(_process_pathnames, num_parallel_calls=threads)\n",
    "    if preproc_fn.keywords is not None and 'resize' not in preproc_fn.keywords:\n",
    "        assert batch_size == 1, \"Imagens no batch não respeitam as mesmas dimensões\"\n",
    "\n",
    "    dataset = dataset.map(preproc_fn, num_parallel_calls=threads)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(num_x)\n",
    "\n",
    "\n",
    "    dataset = dataset.repeat().batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iu5WmYmOwKrV"
   },
   "outputs": [],
   "source": [
    "tr_cfg = {\n",
    "    'resize': [img_shape[0], img_shape[1]],\n",
    "    'scale': 1 / 255.,\n",
    "    'hue_delta': 0.1,\n",
    "    'horizontal_flip': True,\n",
    "    'width_shift_range': 0.1,\n",
    "    'height_shift_range': 0.1\n",
    "}\n",
    "tr_preprocessing_fn = functools.partial(_augment, **tr_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtzLkDFMpF0T"
   },
   "outputs": [],
   "source": [
    "val_cfg = {\n",
    "    'resize': [img_shape[0], img_shape[1]],\n",
    "    'scale': 1 / 255.,\n",
    "}\n",
    "val_preprocessing_fn = functools.partial(_augment, **val_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cNpECdkaafo"
   },
   "outputs": [],
   "source": [
    "train_ds = get_baseline_dataset(X_train_imgs, y_train_filenames,\n",
    "                                preproc_fn = tr_preprocessing_fn, batch_size = batch_size)\n",
    "\n",
    "val_ds = get_baseline_dataset(x_val_filenames, y_val_filenames, \n",
    "                              preproc_fn = val_preprocessing_fn, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KImnu786lAX2"
   },
   "source": [
    "Podemos verificar se o processo está funcionando de maneira adequada verificando o processamento de um primeiro batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjoUqbPdHQej"
   },
   "outputs": [],
   "source": [
    "temp_ds = get_baseline_dataset(X_train_imgs, y_train_filenames, preproc_fn = tr_preprocessing_fn,\n",
    "                               batch_size = 1, shuffle = False)\n",
    "\n",
    "data_aug_iter = temp_ds.make_one_shot_iterator()\n",
    "next_element = data_aug_iter.get_next()\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    batch_of_imgs, label = sess.run(next_element)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    img = batch_of_imgs[0]\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(label[0, :, :, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-19uMx2ilAX3"
   },
   "source": [
    "### CNN U-Net\n",
    "\n",
    "Vamos criar nossa U-Net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfew1i1F6bK-"
   },
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters):\n",
    "    encoder = layers.Conv2D(num_filters, (3, 3), padding = 'same')(input_tensor)\n",
    "    encoder = layers.BatchNormalization()(encoder)\n",
    "    encoder = layers.Activation('relu')(encoder)\n",
    "    encoder = layers.Conv2D(num_filters, (3, 3), padding = 'same')(encoder)\n",
    "    encoder = layers.BatchNormalization()(encoder)\n",
    "    encoder = layers.Activation('relu')(encoder)\n",
    "    return encoder\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "    encoder = conv_block(input_tensor, num_filters)\n",
    "    encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
    "\n",
    "    return encoder_pool, encoder\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "    decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding = 'same')(input_tensor)\n",
    "    decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    decoder = layers.Conv2D(num_filters, (3, 3), padding = 'same')(decoder)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    decoder = layers.Conv2D(num_filters, (3, 3), padding = 'same')(decoder)\n",
    "    decoder = layers.BatchNormalization()(decoder)\n",
    "    decoder = layers.Activation('relu')(decoder)\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xRLp21S_hpTn"
   },
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape = img_shape)\n",
    "encoder0_pool, encoder0 = encoder_block(inputs, 32)\n",
    "encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)\n",
    "encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)\n",
    "encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)\n",
    "encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n",
    "center = conv_block(encoder4_pool, 1024)\n",
    "decoder4 = decoder_block(center, encoder4, 512)\n",
    "decoder3 = decoder_block(decoder4, encoder3, 256)\n",
    "decoder2 = decoder_block(decoder3, encoder2, 128)\n",
    "decoder1 = decoder_block(decoder2, encoder1, 64)\n",
    "decoder0 = decoder_block(decoder1, encoder0, 32)\n",
    "outputs = layers.Conv2D(1, (1, 1), activation = 'sigmoid')(decoder0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76QkTzXVczgc"
   },
   "outputs": [],
   "source": [
    "model = models.Model(inputs = [inputs], outputs = [outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R041TfC4lAX8"
   },
   "source": [
    "### Definindo métricas de loss\n",
    "\n",
    "Aqui precisamos definir nossas funções para contabilizar o erro de saída. Vamos utilizar uma métrica conhecida como Dice Loss.\n",
    "\n",
    "Dice Loss é uma métrica que mede qual é a sobreposição da máscara gerada pela máscara real. Para uma visão mais detalhada da métrica veja [este trabalho](http://campar.in.tum.de/pub/milletari2016Vnet/milletari2016Vnet.pdf) sobre segmentação volumétrica em imagens médicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_8_hbHECUAW"
   },
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DgINhlpNaxP"
   },
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udrfi9JGB-bL"
   },
   "outputs": [],
   "source": [
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gflcWk2Cc8Bi"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = bce_dice_loss, metrics = [dice_loss])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Iy8UzsGlAYD"
   },
   "source": [
    "### Treinamento\n",
    "\n",
    "Por ser um processo lento, vamos configurar um arquivo onde o melhor resultado obtido será salvo, desta maneira, podemos carregar este modelo num futuro para realizar novos testes caso necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1nHnj6199elZ"
   },
   "outputs": [],
   "source": [
    "model_path = './modelo_bc_V1.hdf5'\n",
    "\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath = model_path, \n",
    "                                        monitor = 'val_dice_loss', \n",
    "                                        save_best_only = True, \n",
    "                                        verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMZcOrq5aaj1"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, \n",
    "                    steps_per_epoch = int(np.ceil(num_train_examples / float(batch_size))),\n",
    "                    epochs = epochs,\n",
    "                    validation_data = val_ds,\n",
    "                    validation_steps = int(np.ceil(num_val_examples / float(batch_size))),\n",
    "                    callbacks = [cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvntxymYn8rM"
   },
   "outputs": [],
   "source": [
    "dice = history.history['dice_loss']\n",
    "val_dice = history.history['val_dice_loss']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize = (16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, dice, label = 'Dice Loss - Treinamento')\n",
    "plt.plot(epochs_range, val_dice, label = 'Dice Loss - Validação')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Dice Loss - Treino e Validação')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label = 'Loss - Treinamento')\n",
    "plt.plot(epochs_range, val_loss, label = 'Loss - Validação')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss - Treino e Validação')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ph7acmrCXm6"
   },
   "outputs": [],
   "source": [
    "model = models.load_model(model_path, custom_objects={'bce_dice_loss': bce_dice_loss,\n",
    "                                                      'dice_loss': dice_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "euNWV79vlAYJ"
   },
   "source": [
    "### Resultados\n",
    "\n",
    "Podemos agora verificar qual é o resultado de saída da rede.\n",
    "\n",
    "Vamos plotar a imagem original, sua máscara original e a máscara de saída da rede para comparar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0GnwZ7CPaamI"
   },
   "outputs": [],
   "source": [
    "data_aug_iter = val_ds.make_one_shot_iterator()\n",
    "next_element = data_aug_iter.get_next()\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(6):\n",
    "    batch_of_imgs, label = tf.keras.backend.get_session().run(next_element)\n",
    "    img = batch_of_imgs[0]\n",
    "    predicted_label = model.predict(batch_of_imgs)[0]\n",
    "\n",
    "    plt.subplot(6, 3, 3 * i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Imagem de entrada\")\n",
    "\n",
    "    plt.subplot(6, 3, 3 * i + 2)\n",
    "    plt.imshow(label[0, :, :, 0])\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Máscara real\")\n",
    "    plt.subplot(6, 3, 3 * i + 3)\n",
    "    plt.imshow(predicted_label[:, :, 0])\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Output do modelo\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Atividade1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
